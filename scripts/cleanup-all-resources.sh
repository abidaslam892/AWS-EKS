#!/bin/bash

# Complete AWS Resources Cleanup Script
# This script will delete ALL resources created by the EKS setup to prevent revenue leakage

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
MAGENTA='\033[0;35m'
NC='\033[0m' # No Color

CLUSTER_NAME="my-eks-cluster"
REGION="us-east-1"

echo -e "${RED}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
echo -e "${RED}â•‘              ðŸš¨ COMPLETE RESOURCE CLEANUP ðŸš¨              â•‘${NC}"
echo -e "${RED}â•‘                                                          â•‘${NC}"
echo -e "${RED}â•‘  This will DELETE ALL AWS resources to prevent costs!   â•‘${NC}"
echo -e "${RED}â•‘  âš ï¸  This action is IRREVERSIBLE âš ï¸                      â•‘${NC}"
echo -e "${RED}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo ""

# Navigate to project directory
cd /home/abid/Project/AWS-Project

# Function to show progress
show_progress() {
    echo -e "${CYAN}[$(date '+%H:%M:%S')] $1${NC}"
}

# Function to check if resource exists
resource_exists() {
    local check_command="$1"
    eval "$check_command" > /dev/null 2>&1
    return $?
}

# Confirmation prompt
echo -e "${YELLOW}This script will delete the following resources:${NC}"
echo -e "${MAGENTA}ðŸ“Š EKS Resources:${NC}"
echo "  â€¢ EKS Cluster: $CLUSTER_NAME"
echo "  â€¢ All Fargate Profiles (default-fargate, fargate-namespace, app-fargate, frontend-fargate)"
echo "  â€¢ All Node Groups"
echo "  â€¢ OIDC Identity Provider"
echo ""
echo -e "${MAGENTA}ðŸ—ï¸ Infrastructure:${NC}"
echo "  â€¢ VPC and associated subnets"
echo "  â€¢ Security Groups"
echo "  â€¢ Internet Gateway & Route Tables"
echo "  â€¢ NAT Gateways (if created)"
echo "  â€¢ Elastic IPs"
echo ""
echo -e "${MAGENTA}â˜ï¸ Kubernetes Resources:${NC}"
echo "  â€¢ All deployed applications"
echo "  â€¢ Load Balancers (Classic & Network)"
echo "  â€¢ Persistent Volumes & EBS volumes"
echo "  â€¢ ConfigMaps & Secrets"
echo ""
echo -e "${MAGENTA}ðŸ“ Additional Services:${NC}"
echo "  â€¢ CloudWatch Log Groups"
echo "  â€¢ IAM Roles & Policies (EKS related)"
echo "  â€¢ Service Accounts"
echo ""
echo -e "${RED}ðŸ’° Estimated monthly cost being eliminated: ~$157.40${NC}"
echo ""

read -p "$(echo -e ${YELLOW}Are you absolutely sure you want to delete ALL resources? Type 'DELETE' to confirm: ${NC})" -r
echo
if [[ ! $REPLY == "DELETE" ]]; then
    echo -e "${GREEN}âœ… Cleanup cancelled. Resources are safe.${NC}"
    exit 0
fi

echo ""
echo -e "${RED}ðŸš¨ Starting complete resource cleanup...${NC}"
echo ""

# Step 1: Delete Kubernetes applications first
show_progress "ðŸ§¹ Cleaning up Kubernetes applications..."

if kubectl get nodes > /dev/null 2>&1; then
    echo -e "${YELLOW}Deleting all deployed applications...${NC}"
    
    # Delete Fargate test apps
    kubectl delete -f manifests/fargate-test-pod.yaml --ignore-not-found=true
    kubectl delete -f manifests/fargate-app.yaml --ignore-not-found=true
    kubectl delete -f manifests/frontend-fargate.yaml --ignore-not-found=true
    
    # Delete regular test apps
    kubectl delete -f manifests/test-pod.yaml --ignore-not-found=true
    kubectl delete -f manifests/nginx-deployment.yaml --ignore-not-found=true
    
    # Delete all services to remove load balancers
    echo -e "${YELLOW}Deleting all LoadBalancer services...${NC}"
    kubectl delete services --all --all-namespaces --wait=true
    
    # Delete all persistent volume claims
    echo -e "${YELLOW}Deleting persistent volume claims...${NC}"
    kubectl delete pvc --all --all-namespaces --wait=true
    
    # Wait for load balancers to be cleaned up
    echo -e "${YELLOW}Waiting for AWS Load Balancers to be deleted...${NC}"
    sleep 30
    
    echo -e "${GREEN}âœ… Kubernetes applications cleaned up${NC}"
else
    echo -e "${YELLOW}âš ï¸ Cannot connect to cluster, skipping application cleanup${NC}"
fi

# Step 2: Delete Fargate Profiles
show_progress "ðŸ”„ Deleting Fargate Profiles..."

fargate_profiles=("default-fargate" "fargate-namespace" "app-fargate" "frontend-fargate")

for profile in "${fargate_profiles[@]}"; do
    echo -e "${YELLOW}Deleting Fargate profile: $profile${NC}"
    if resource_exists "./eksctl get fargateprofile --cluster $CLUSTER_NAME --name $profile --region $REGION"; then
        ./eksctl delete fargateprofile --cluster $CLUSTER_NAME --name $profile --region $REGION --wait
        echo -e "${GREEN}âœ… Deleted Fargate profile: $profile${NC}"
    else
        echo -e "${CYAN}â„¹ï¸ Fargate profile $profile not found, skipping${NC}"
    fi
    sleep 5
done

# Step 3: Delete Node Groups (if any)
show_progress "ðŸ–¥ï¸ Deleting Node Groups..."

if resource_exists "./eksctl get nodegroup --cluster $CLUSTER_NAME --region $REGION"; then
    echo -e "${YELLOW}Found node groups, deleting...${NC}"
    ./eksctl delete nodegroup --cluster $CLUSTER_NAME --region $REGION --approve --wait
    echo -e "${GREEN}âœ… Node groups deleted${NC}"
else
    echo -e "${CYAN}â„¹ï¸ No node groups found${NC}"
fi

# Step 4: Delete the EKS Cluster
show_progress "ðŸŽ¯ Deleting EKS Cluster..."

if resource_exists "./eksctl get cluster --name $CLUSTER_NAME --region $REGION"; then
    echo -e "${YELLOW}Deleting EKS cluster: $CLUSTER_NAME${NC}"
    echo -e "${YELLOW}This may take 10-15 minutes...${NC}"
    
    ./eksctl delete cluster --name $CLUSTER_NAME --region $REGION --wait
    
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}âœ… EKS cluster deleted successfully${NC}"
    else
        echo -e "${RED}âŒ Failed to delete EKS cluster${NC}"
        echo -e "${YELLOW}You may need to manually clean up remaining resources in AWS Console${NC}"
    fi
else
    echo -e "${CYAN}â„¹ï¸ EKS cluster not found${NC}"
fi

# Step 5: Clean up orphaned resources
show_progress "ðŸ§½ Cleaning up orphaned AWS resources..."

echo -e "${YELLOW}Checking for orphaned Load Balancers...${NC}"
# List any remaining load balancers
aws elbv2 describe-load-balancers --region $REGION --query 'LoadBalancers[?contains(LoadBalancerName, `k8s-`) || contains(Tags[?Key==`kubernetes.io/cluster/my-eks-cluster`], `owned`)].LoadBalancerArn' --output text 2>/dev/null | while read lb_arn; do
    if [ ! -z "$lb_arn" ]; then
        echo -e "${YELLOW}Deleting orphaned ALB/NLB: $lb_arn${NC}"
        aws elbv2 delete-load-balancer --load-balancer-arn "$lb_arn" --region $REGION
    fi
done

# Clean up Classic Load Balancers
aws elb describe-load-balancers --region $REGION --query 'LoadBalancerDescriptions[?contains(LoadBalancerName, `k8s-`) || contains(Tags[?Key==`kubernetes.io/cluster/my-eks-cluster`], `owned`)].LoadBalancerName' --output text 2>/dev/null | while read lb_name; do
    if [ ! -z "$lb_name" ]; then
        echo -e "${YELLOW}Deleting orphaned Classic LB: $lb_name${NC}"
        aws elb delete-load-balancer --load-balancer-name "$lb_name" --region $REGION
    fi
done

echo -e "${YELLOW}Checking for orphaned EBS volumes...${NC}"
# Clean up unattached EBS volumes with kubernetes tags
aws ec2 describe-volumes --region $REGION --filters "Name=tag:kubernetes.io/cluster/$CLUSTER_NAME,Values=owned" "Name=state,Values=available" --query 'Volumes[].VolumeId' --output text 2>/dev/null | while read volume_id; do
    if [ ! -z "$volume_id" ]; then
        echo -e "${YELLOW}Deleting orphaned EBS volume: $volume_id${NC}"
        aws ec2 delete-volume --volume-id "$volume_id" --region $REGION
    fi
done

# Step 6: Clean up CloudWatch Log Groups
show_progress "ðŸ“ Cleaning up CloudWatch Log Groups..."

echo -e "${YELLOW}Deleting EKS-related CloudWatch log groups...${NC}"
aws logs describe-log-groups --region $REGION --log-group-name-prefix "/aws/eks/$CLUSTER_NAME" --query 'logGroups[].logGroupName' --output text 2>/dev/null | while read log_group; do
    if [ ! -z "$log_group" ]; then
        echo -e "${YELLOW}Deleting log group: $log_group${NC}"
        aws logs delete-log-group --log-group-name "$log_group" --region $REGION
    fi
done

# Step 7: Summary and cost verification
show_progress "ðŸ“Š Cleanup Summary"

echo ""
echo -e "${GREEN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
echo -e "${GREEN}â•‘                    âœ… CLEANUP COMPLETE âœ…                  â•‘${NC}"
echo -e "${GREEN}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
echo ""

echo -e "${BLUE}ðŸŽ¯ Resources Cleaned Up:${NC}"
echo -e "${GREEN}âœ… EKS Cluster: $CLUSTER_NAME${NC}"
echo -e "${GREEN}âœ… All Fargate Profiles${NC}"
echo -e "${GREEN}âœ… All Node Groups${NC}"
echo -e "${GREEN}âœ… Kubernetes Applications${NC}"
echo -e "${GREEN}âœ… Load Balancers${NC}"
echo -e "${GREEN}âœ… EBS Volumes${NC}"
echo -e "${GREEN}âœ… CloudWatch Log Groups${NC}"
echo ""

echo -e "${MAGENTA}ðŸ’° Cost Savings:${NC}"
echo -e "${GREEN}â€¢ Monthly savings: ~$157.40${NC}"
echo -e "${GREEN}â€¢ Yearly savings: ~$1,888.80${NC}"
echo ""

echo -e "${BLUE}ðŸ” Verification Steps:${NC}"
echo -e "${YELLOW}1. Check AWS Console - EKS:${NC} https://console.aws.amazon.com/eks/home?region=$REGION"
echo -e "${YELLOW}2. Check Load Balancers:${NC} https://console.aws.amazon.com/ec2/v2/home?region=$REGION#LoadBalancers:"
echo -e "${YELLOW}3. Check EBS Volumes:${NC} https://console.aws.amazon.com/ec2/v2/home?region=$REGION#Volumes:"
echo -e "${YELLOW}4. Check your AWS bill in 24-48 hours to confirm cost reduction${NC}"
echo ""

echo -e "${CYAN}ðŸ’¡ Pro Tip: Set up AWS billing alerts to monitor future costs!${NC}"
echo ""

# Remove kubeconfig
if [ -f ~/.kube/config ]; then
    echo -e "${YELLOW}Cleaning up local kubeconfig...${NC}"
    kubectl config delete-cluster "$CLUSTER_NAME" 2>/dev/null || true
    kubectl config delete-context "$CLUSTER_NAME" 2>/dev/null || true
    kubectl config unset users."$CLUSTER_NAME" 2>/dev/null || true
    echo -e "${GREEN}âœ… Local kubeconfig cleaned${NC}"
fi

echo -e "${GREEN}ðŸŽ‰ All AWS resources have been successfully deleted!${NC}"
echo -e "${GREEN}ðŸ’¸ No more charges will be incurred from these resources.${NC}"